{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756095dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.fetch.google_api:\n",
      "Found restaurant: FunkyFisch\n",
      "Kantstra√üe 135-136, 10625 Berlin, Deutschland\n",
      "ID = ChIJU7-KvONQqEcRCmPCCvo-Fg4\n",
      "\n",
      "INFO:src.fetch.google_api:\n",
      "Found restaurant: Standard Serious Pizza Charlottenburg\n",
      "Schl√ºterstra√üe 63, 10625 Berlin, Deutschland\n",
      "ID = ChIJc2uwDI1RqEcRfAsy3YxyfIY\n",
      "\n",
      "INFO:src.fetch.google_api:\n",
      "Found restaurant: Borchardt\n",
      "Franz√∂sische Str. 47, 10117 Berlin, Deutschland\n",
      "ID = ChIJVfEmINtRqEcRsch0pslaanQ\n",
      "\n",
      "INFO:src.fetch.google_api:\n",
      "Found restaurant: Gio's\n",
      "Dresdener Str. 16, 10999 Berlin, Deutschland\n",
      "ID = ChIJ65Liv5JPqEcRodr8aFFNAvE\n",
      "\n",
      "INFO:src.fetch.google_api:\n",
      "Found restaurant: Hasir Kreuzberg\n",
      "Adalbertstra√üe 10, 10999 Berlin, Deutschland\n",
      "ID = ChIJZ-8TQ8hPqEcRf0R-vl8UwwY\n",
      "\n",
      "INFO:src.fetch.google_api:\n",
      "Found restaurant: Paolo Pinkel\n",
      "Karl-Marx-Stra√üe 55, 12043 Berlin, Deutschland\n",
      "ID = ChIJpRECXmtPqEcRJMfokCTNvD8\n",
      "\n",
      "INFO:src.fetch.google_api:\n",
      "Found restaurant: FunkyFisch\n",
      "Kantstra√üe 135-136, 10625 Berlin, Germany\n",
      "\n",
      "INFO:src.fetch.google_api:Retrieved 5 reviews for FunkyFisch ‚úÖ\n",
      "INFO:src.fetch.google_api:\n",
      "Found restaurant: Standard Pizza West\n",
      "Schl√ºterstra√üe 63, 10625 Berlin, Germany\n",
      "\n",
      "INFO:src.fetch.google_api:Retrieved 5 reviews for Standard Pizza West ‚úÖ\n",
      "INFO:src.fetch.google_api:\n",
      "Found restaurant: Borchardt\n",
      "Franz√∂sische Str. 47, 10117 Berlin, Germany\n",
      "\n",
      "INFO:src.fetch.google_api:Retrieved 5 reviews for Borchardt ‚úÖ\n",
      "INFO:src.fetch.google_api:\n",
      "Found restaurant: Gio's\n",
      "Dresdener Str. 16, 10999 Berlin, Germany\n",
      "\n",
      "INFO:src.fetch.google_api:Retrieved 5 reviews for Gio's ‚úÖ\n",
      "INFO:src.fetch.google_api:\n",
      "Found restaurant: Hasir Kreuzberg\n",
      "Adalbertstra√üe 10, 10999 Berlin, Germany\n",
      "\n",
      "INFO:src.fetch.google_api:Retrieved 5 reviews for Hasir Kreuzberg ‚úÖ\n",
      "INFO:src.fetch.google_api:\n",
      "Found restaurant: Paolo Pinkel\n",
      "Karl-Marx-Stra√üe 55, 12043 Berlin, Germany\n",
      "\n",
      "INFO:src.fetch.google_api:Retrieved 5 reviews for Paolo Pinkel ‚úÖ\n"
     ]
    }
   ],
   "source": [
    "# set correct path for imports for this notebook\n",
    "import sys, os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\")))\n",
    "\n",
    "# external imports \n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# local imports\n",
    "from src.fetch.google_api import fetch_google_places_data\n",
    "from src.fetch.google_api import fetch_place_id\n",
    "from src.nlp.extractor_openai import extract_dishes_openai, _cached_extract_single\n",
    "from src.ranking.scoring import assign_dish_scores\n",
    "from src.recommendation.recs import form_recommendations\n",
    "\n",
    "# Clear dish extractor cache to ensure fresh model load\n",
    "_cached_extract_single.cache_clear()\n",
    "\n",
    "# Restaurants to test with\n",
    "r1_id = fetch_place_id(\"funkyfish berlin\")\n",
    "r2_id = fetch_place_id(\"standard pizza west berlin\")\n",
    "r3_id = fetch_place_id(\"borschert berlin\")\n",
    "r4_id = fetch_place_id(\"Gio's Berlin\") \n",
    "r5_id = fetch_place_id(\"hasir kreuzberg\")\n",
    "r6_id = fetch_place_id(\"paolo pinkel berlin\")\n",
    "\n",
    "# Getting restaurant info and reviews\n",
    "r1, funky = fetch_google_places_data(r1_id)\n",
    "r2, pizza = fetch_google_places_data(r2_id)\n",
    "r3, borch = fetch_google_places_data(r3_id)\n",
    "r4, gio  = fetch_google_places_data(r4_id)\n",
    "r5, hasir = fetch_google_places_data(r5_id)\n",
    "r6, paolo = fetch_google_places_data(r6_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "1a5cc6b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.nlp.extractor_openai:üöÄ Starting async extraction for 5 chunks...\n",
      "INFO:src.nlp.extractor_openai:üçΩÔ∏è Extracted from Review #1: none\n",
      "INFO:src.nlp.extractor_openai:üçΩÔ∏è Extracted from Review #2: roastbeef, schnitzel, ceviche\n",
      "INFO:src.nlp.extractor_openai:üçΩÔ∏è Extracted from Review #3: fries, fried chicken\n",
      "INFO:src.nlp.extractor_openai:üçΩÔ∏è Extracted from Review #4: none\n",
      "INFO:src.nlp.extractor_openai:üçΩÔ∏è Extracted from Review #5: kimcheese fries, korean fried chicken\n",
      "INFO:src.nlp.extractor_openai:‚úÖ Completed dish extraction for 5 reviews in 0.03s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IPython autoawait is `on`, and set to use `asyncio`\n"
     ]
    }
   ],
   "source": [
    "# Extracting dishes\n",
    "restaurant = paolo #change restaurant here\n",
    "\n",
    "%autoawait\n",
    "review_with_dishes = await extract_dishes_openai(restaurant, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf75e02",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 75)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mFile \u001b[39m\u001b[32m<tokenize>:75\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mlogger.info(\"=\" * 40)\u001b[39m\n    ^\n\u001b[31mIndentationError\u001b[39m\u001b[31m:\u001b[39m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "# only relevant in notebook to do reruns\n",
    "import copy\n",
    "reviews = copy.deepcopy(review_with_dishes)\n",
    "\n",
    "# import\n",
    "import logging\n",
    "logger = logging.getLogger(__name__)\n",
    "from typing import Dict, List, Any\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "\n",
    "# helper function\n",
    "def count_words(string:str) -> int:\n",
    "    \"\"\"\n",
    "    Counts words in a given string.\n",
    "    \"\"\"\n",
    "    word_count = len(string.split())\n",
    "    return word_count\n",
    "\n",
    "\n",
    "\n",
    "# main function\n",
    "def assign_dish_scores(reviews: List[Dict[str, Any]]) -> None:\n",
    "    \"\"\"\n",
    "    Assigns scores to dishes based on review source, author name, and dish name length.\n",
    "\n",
    "    Google reviews get a small author bonus; blog reviews start with higher base points.\n",
    "    Longer dish names earn extra points up to a cap. Logs all scoring steps.\n",
    "\n",
    "    Args:\n",
    "        reviews: List of review dicts with 'source_type', 'author', and 'dishes'.\n",
    "    \"\"\"\n",
    "    \n",
    "    # constants\n",
    "    google_default_points = 0\n",
    "    blog_default_points = 1000\n",
    "    \n",
    "    logger.info(\"=\" * 16 + \" SCORING \" +\"=\" * 15 )\n",
    "\n",
    "    if any(\n",
    "        dish.get(\"ranking\") is not None\n",
    "        for review in reviews\n",
    "        if review.get(\"dishes\")\n",
    "        for dish in review[\"dishes\"]\n",
    "    ):\n",
    "        logger.info(\"This review set already contains ranked dishes. Skipping scoring.\")\n",
    "    else:\n",
    "        for i, review in enumerate(reviews):\n",
    "                # variables\n",
    "                final_score: int = 0\n",
    "                author_p: int = 0\n",
    "                source_p: int = 0\n",
    "                dish_name_p: int = 0\n",
    "\n",
    "                # scoring source type\n",
    "                if review.get(\"source_type\") == \"google\" and review.get(\"dishes\"):\n",
    "                    source_p = google_default_points\n",
    "                    if count_words(review.get(\"author\",\"\")) > 1:\n",
    "                        author_p = 10 # rewards real min. two word names for google reviewrs\n",
    "\n",
    "                elif review.get(\"source_type\") == \"blog\" and review.get(\"dishes\"): \n",
    "                    source_p = blog_default_points\n",
    "\n",
    "                # scoring dish based on number of words         \n",
    "                for dish in review[\"dishes\"]:\n",
    "                    dish_name_p = 0\n",
    "                    if dish.get(\"ranking\") is None:\n",
    "                        dish_name = dish.get(\"name\")\n",
    "                        word_count = len(dish_name.split())\n",
    "                        dish_name_p = min(word_count**3, 50) # reward more words exponentially with a cap on 4\n",
    "                    \n",
    "                        final_score = author_p + source_p + dish_name_p\n",
    "                        dish[\"ranking\"] = final_score\n",
    "                        logger.info(f\"SCORE: Review #{i+1} -- {final_score}p -- {dish.get('name')} -- ({source_p} +{author_p} +{dish_name_p})\")  \n",
    "                logger.info(\"=\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "498fa37b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:================ SCORING ===============\n",
      "INFO:__main__:SCORE: Review #2 -- 11p -- roastbeef -- (0 +10 +1)\n",
      "INFO:__main__:========================================\n",
      "INFO:__main__:SCORE: Review #2 -- 11p -- schnitzel -- (0 +10 +1)\n",
      "INFO:__main__:========================================\n",
      "INFO:__main__:SCORE: Review #2 -- 11p -- ceviche -- (0 +10 +1)\n",
      "INFO:__main__:========================================\n",
      "INFO:__main__:SCORE: Review #3 -- 11p -- fries -- (0 +10 +1)\n",
      "INFO:__main__:========================================\n",
      "INFO:__main__:SCORE: Review #3 -- 18p -- fried chicken -- (0 +10 +8)\n",
      "INFO:__main__:========================================\n",
      "INFO:__main__:SCORE: Review #5 -- 18p -- kimcheese fries -- (0 +10 +8)\n",
      "INFO:__main__:========================================\n",
      "INFO:__main__:SCORE: Review #5 -- 37p -- korean fried chicken -- (0 +10 +27)\n",
      "INFO:__main__:========================================\n"
     ]
    }
   ],
   "source": [
    "assign_dish_scores(paolo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "649be977",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.recommendation.recs:üçΩÔ∏è Generated 7 recommendations from 5 reviews.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'dish_name': 'roastbeef',\n",
       "  'ranking': 10,\n",
       "  'author': 'Deer Ozzie',\n",
       "  'source': 'Google Reviews',\n",
       "  'timestamp': 1749415038,\n",
       "  'review_link': HttpUrl('https://www.google.com/maps/reviews/data=!4m6!14m5!1m4!2m3!1sChZDSUhNMG9nS0VNNjQ4T2ltZzlxTUl3EAE!2m1!1s0x47a84f6b5e0211a5:0x3fbccd2490e8c724')},\n",
       " {'dish_name': 'schnitzel',\n",
       "  'ranking': 10,\n",
       "  'author': 'Deer Ozzie',\n",
       "  'source': 'Google Reviews',\n",
       "  'timestamp': 1749415038,\n",
       "  'review_link': HttpUrl('https://www.google.com/maps/reviews/data=!4m6!14m5!1m4!2m3!1sChZDSUhNMG9nS0VNNjQ4T2ltZzlxTUl3EAE!2m1!1s0x47a84f6b5e0211a5:0x3fbccd2490e8c724')},\n",
       " {'dish_name': 'ceviche',\n",
       "  'ranking': 10,\n",
       "  'author': 'Deer Ozzie',\n",
       "  'source': 'Google Reviews',\n",
       "  'timestamp': 1749415038,\n",
       "  'review_link': HttpUrl('https://www.google.com/maps/reviews/data=!4m6!14m5!1m4!2m3!1sChZDSUhNMG9nS0VNNjQ4T2ltZzlxTUl3EAE!2m1!1s0x47a84f6b5e0211a5:0x3fbccd2490e8c724')},\n",
       " {'dish_name': 'fries',\n",
       "  'ranking': 10,\n",
       "  'author': 'M K',\n",
       "  'source': 'Google Reviews',\n",
       "  'timestamp': 1743849235,\n",
       "  'review_link': HttpUrl('https://www.google.com/maps/reviews/data=!4m6!14m5!1m4!2m3!1sChdDSUhNMG9nS0VJQ0FnTUNJdF9iWmdRRRAB!2m1!1s0x47a84f6b5e0211a5:0x3fbccd2490e8c724')},\n",
       " {'dish_name': 'fried chicken',\n",
       "  'ranking': 10,\n",
       "  'author': 'M K',\n",
       "  'source': 'Google Reviews',\n",
       "  'timestamp': 1743849235,\n",
       "  'review_link': HttpUrl('https://www.google.com/maps/reviews/data=!4m6!14m5!1m4!2m3!1sChdDSUhNMG9nS0VJQ0FnTUNJdF9iWmdRRRAB!2m1!1s0x47a84f6b5e0211a5:0x3fbccd2490e8c724')},\n",
       " {'dish_name': 'kimcheese fries',\n",
       "  'ranking': 10,\n",
       "  'author': 'Nadine Co',\n",
       "  'source': 'Google Reviews',\n",
       "  'timestamp': 1740520451,\n",
       "  'review_link': HttpUrl('https://www.google.com/maps/reviews/data=!4m6!14m5!1m4!2m3!1sChdDSUhNMG9nS0VJQ0FnTURnbWZYMHlRRRAB!2m1!1s0x47a84f6b5e0211a5:0x3fbccd2490e8c724')},\n",
       " {'dish_name': 'korean fried chicken',\n",
       "  'ranking': 10,\n",
       "  'author': 'Nadine Co',\n",
       "  'source': 'Google Reviews',\n",
       "  'timestamp': 1740520451,\n",
       "  'review_link': HttpUrl('https://www.google.com/maps/reviews/data=!4m6!14m5!1m4!2m3!1sChdDSUhNMG9nS0VJQ0FnTURnbWZYMHlRRRAB!2m1!1s0x47a84f6b5e0211a5:0x3fbccd2490e8c724')}]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "form_recommendations(paolo)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
